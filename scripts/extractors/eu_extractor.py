"""
EU (European Union) PDF Extractor

å¾æ­ç›ŸåŒ–å¦å“æ³•è¦PDFä¸­æå–æ•¸æ“šã€‚

æ•¸æ“šä¾†æºï¼š
- Regulation (EC) No 1223/2009
- 5å€‹Annex PDFæ–‡ä»¶ï¼š
  * é™„ä»¶1-1: LIST OF SUBSTANCES PROHIBITED (Annex II)
  * é™„ä»¶1-2: LIST OF SUBSTANCES RESTRICTED (Annex III)
  * é™„ä»¶1-3: LIST OF COLORANTS ALLOWED (Annex IV)
  * é™„ä»¶1-4: LIST OF PRESERVATIVES ALLOWED (Annex V)
  * é™„ä»¶1-5: LIST OF UV FILTERS ALLOWED (Annex VI)
"""

from pathlib import Path
from typing import Dict, List, Any
from .base_extractor import BasePDFExtractor


class EUExtractor(BasePDFExtractor):
    """æ­ç›Ÿæ³•è¦PDFæå–å™¨"""

    def __init__(self):
        super().__init__("EU")

        # PDFæ–‡ä»¶æ˜ å°„
        self.pdf_mappings = {
            "prohibited": {
                "name": "Annex II - Prohibited Substances",
                "filename_pattern": "*é™„ä»¶1-1*PROHIBITED*.pdf",
                "keywords": ["Annex II", "PROHIBITED", "Reference number"],
            },
            "restricted": {
                "name": "Annex III - Restricted Substances",
                "filename_pattern": "*é™„ä»¶1-2*.pdf",
                "keywords": ["Annex III", "RESTRICTED", "Reference number"],
            },
            "colorants": {
                "name": "Annex IV - Colorants",
                "filename_pattern": "*é™„ä»¶1-3*COLORANTS*.pdf",
                "keywords": ["Annex IV", "COLORANTS", "Colour Index"],
            },
            "preservatives": {
                "name": "Annex V - Preservatives",
                "filename_pattern": "*é™„ä»¶1-4*PRESERVATIVES*.pdf",
                "keywords": ["Annex V", "PRESERVATIVES", "Reference number"],
            },
            "uv_filters": {
                "name": "Annex VI - UV Filters",
                "filename_pattern": "*é™„ä»¶1-5*UV*.pdf",
                "keywords": ["Annex VI", "UV", "Reference number"],
            }
        }

    def extract(self) -> Dict[str, Any]:
        """
        æå–EUæ³•è¦æ•¸æ“š

        Returns:
            æå–çš„æ•¸æ“šå­—å…¸
        """
        print(f"ğŸ“ æƒæPDFæ–‡ä»¶...")

        all_data = {}
        total_count = 0

        for table_type, config in self.pdf_mappings.items():
            print(f"\nè™•ç† {config['name']}...")

            # æŸ¥æ‰¾å°æ‡‰çš„PDF
            pdf_files = list(self.raw_data_dir.glob(config["filename_pattern"]))

            if not pdf_files:
                print(f"   âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {config['filename_pattern']}")
                all_data[table_type] = {
                    "name": config["name"],
                    "status": "file_not_found",
                    "ingredients_count": 0,
                    "ingredients": []
                }
                continue

            pdf_path = pdf_files[0]
            print(f"   ğŸ“„ {pdf_path.name}")

            # æå–è¡¨æ ¼æ•¸æ“š
            data = self.extract_annex_table(pdf_path, config)
            all_data[table_type] = data
            total_count += data.get("ingredients_count", 0)

        # ç”Ÿæˆè¼¸å‡º
        output = {
            "jurisdiction": "EU",
            "source": "European Commission - CosIng Database",
            "source_url": "https://ec.europa.eu/growth/tools-databases/cosing/",
            "regulation": "Regulation (EC) No 1223/2009",
            "metadata": self.create_metadata(
                total_ingredients=total_count,
                source="European Commission - CosIng Database",
                regulation="Regulation (EC) No 1223/2009",
                published_at="2024-04-04",
                effective_date="2024-04-24"
            ),
            "annexes": all_data
        }

        # ä¿å­˜çµæœ
        self.save_json(output, "extracted_latest.json")

        return output

    def extract_annex_table(self, pdf_path: Path, config: Dict) -> Dict[str, Any]:
        """
        æå–å–®å€‹Annexè¡¨æ ¼

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾‘
            config: è¡¨æ ¼é…ç½®

        Returns:
            æå–çš„æ•¸æ“š
        """
        try:
            # ä½¿ç”¨PyPDF2æå–æ–‡æœ¬
            texts = self.extract_text_pypdf2(pdf_path)

            # æŸ¥æ‰¾è¡¨æ ¼é–‹å§‹
            start_page = self.find_table_start(texts, config["keywords"])

            if start_page is None:
                print(f"   âš ï¸  æœªæ‰¾åˆ°è¡¨æ ¼é–‹å§‹æ¨™è¨˜")
                return {
                    "name": config["name"],
                    "pdf_file": pdf_path.name,
                    "ingredients_count": 0,
                    "ingredients": [],
                    "extraction_status": "pending",
                    "note": "éœ€è¦åœ¨æœ¬åœ°ç’°å¢ƒæˆ–CIä¸­ä½¿ç”¨pdfplumberæå–å®Œæ•´è¡¨æ ¼æ•¸æ“š"
                }

            print(f"   âœ“ è¡¨æ ¼é–‹å§‹æ–¼ç¬¬ {start_page + 1} é ")

            return {
                "name": config["name"],
                "pdf_file": pdf_path.name,
                "pdf_path": str(pdf_path),
                "table_start_page": start_page + 1,
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "pending",
                "note": "éœ€è¦åœ¨æœ¬åœ°ç’°å¢ƒæˆ–CIä¸­ä½¿ç”¨pdfplumberæå–å®Œæ•´è¡¨æ ¼æ•¸æ“š"
            }

        except Exception as e:
            print(f"   âŒ æå–å¤±æ•—: {str(e)}")
            return {
                "name": config["name"],
                "pdf_file": pdf_path.name,
                "error": str(e),
                "ingredients_count": 0,
                "ingredients": []
            }


if __name__ == "__main__":
    extractor = EUExtractor()
    result = extractor.run()
    print(f"\næå–çµæœæ‘˜è¦:")
    print(f"ç¸½è¨˜éŒ„æ•¸: {result['metadata']['total_ingredients']}")
