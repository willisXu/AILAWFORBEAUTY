"""
EU (European Union) PDF Extractor

å¾æ­ç›ŸåŒ–å¦å“æ³•è¦PDFä¸­æå–æ•¸æ“šã€‚

æ•¸æ“šä¾†æºï¼š
- Regulation (EC) No 1223/2009
- 5å€‹Annex PDFæ–‡ä»¶ï¼š
  * é™„ä»¶1-1: LIST OF SUBSTANCES PROHIBITED (Annex II)
  * é™„ä»¶1-2: LIST OF SUBSTANCES RESTRICTED (Annex III)
  * é™„ä»¶1-3: LIST OF COLORANTS ALLOWED (Annex IV)
  * é™„ä»¶1-4: LIST OF PRESERVATIVES ALLOWED (Annex V)
  * é™„ä»¶1-5: LIST OF UV FILTERS ALLOWED (Annex VI)
"""

from pathlib import Path
from typing import Dict, List, Any
from .base_extractor import BasePDFExtractor


class EUExtractor(BasePDFExtractor):
    """æ­ç›Ÿæ³•è¦PDFæå–å™¨"""

    def __init__(self):
        super().__init__("EU")

        # PDFæ–‡ä»¶æ˜ å°„
        self.pdf_mappings = {
            "prohibited": {
                "name": "Annex II - Prohibited Substances",
                "filename_pattern": "*é™„ä»¶1-1*PROHIBITED*.pdf",
                "keywords": ["Annex II", "PROHIBITED", "Reference number"],
            },
            "restricted": {
                "name": "Annex III - Restricted Substances",
                "filename_pattern": "*é™„ä»¶1-2*.pdf",
                "keywords": ["Annex III", "RESTRICTED", "Reference number"],
            },
            "colorants": {
                "name": "Annex IV - Colorants",
                "filename_pattern": "*é™„ä»¶1-3*COLORANTS*.pdf",
                "keywords": ["Annex IV", "COLORANTS", "Colour Index"],
            },
            "preservatives": {
                "name": "Annex V - Preservatives",
                "filename_pattern": "*é™„ä»¶1-4*PRESERVATIVES*.pdf",
                "keywords": ["Annex V", "PRESERVATIVES", "Reference number"],
            },
            "uv_filters": {
                "name": "Annex VI - UV Filters",
                "filename_pattern": "*é™„ä»¶1-5*UV*.pdf",
                "keywords": ["Annex VI", "UV", "Reference number"],
            }
        }

    def extract(self) -> Dict[str, Any]:
        """
        æå–EUæ³•è¦æ•¸æ“š

        Returns:
            æå–çš„æ•¸æ“šå­—å…¸
        """
        print(f"ğŸ“ æƒæPDFæ–‡ä»¶...")

        all_data = {}
        total_count = 0

        for table_type, config in self.pdf_mappings.items():
            print(f"\nè™•ç† {config['name']}...")

            # æŸ¥æ‰¾å°æ‡‰çš„PDF
            pdf_files = list(self.raw_data_dir.glob(config["filename_pattern"]))

            if not pdf_files:
                print(f"   âš ï¸  æœªæ‰¾åˆ°æ–‡ä»¶: {config['filename_pattern']}")
                all_data[table_type] = {
                    "name": config["name"],
                    "status": "file_not_found",
                    "ingredients_count": 0,
                    "ingredients": []
                }
                continue

            pdf_path = pdf_files[0]
            print(f"   ğŸ“„ {pdf_path.name}")

            # æå–è¡¨æ ¼æ•¸æ“š
            data = self.extract_annex_table(pdf_path, config)
            all_data[table_type] = data
            total_count += data.get("ingredients_count", 0)

        # ç”Ÿæˆè¼¸å‡º
        output = {
            "jurisdiction": "EU",
            "source": "European Commission - CosIng Database",
            "source_url": "https://ec.europa.eu/growth/tools-databases/cosing/",
            "regulation": "Regulation (EC) No 1223/2009",
            "metadata": self.create_metadata(
                total_ingredients=total_count,
                source="European Commission - CosIng Database",
                regulation="Regulation (EC) No 1223/2009",
                published_at="2024-04-04",
                effective_date="2024-04-24"
            ),
            "annexes": all_data
        }

        # ä¿å­˜çµæœ
        self.save_json(output, "extracted_latest.json")

        return output

    def extract_annex_table(self, pdf_path: Path, config: Dict) -> Dict[str, Any]:
        """
        æå–å–®å€‹Annexè¡¨æ ¼

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾‘
            config: è¡¨æ ¼é…ç½®

        Returns:
            æå–çš„æ•¸æ“š
        """
        try:
            # ä½¿ç”¨PyPDF2æå–æ–‡æœ¬
            texts = self.extract_text_pypdf2(pdf_path)

            # æŸ¥æ‰¾è¡¨æ ¼é–‹å§‹
            start_page = self.find_table_start(texts, config["keywords"])

            if start_page is None:
                print(f"   âš ï¸  æœªæ‰¾åˆ°è¡¨æ ¼é–‹å§‹æ¨™è¨˜")
                return {
                    "name": config["name"],
                    "pdf_file": pdf_path.name,
                    "ingredients_count": 0,
                    "ingredients": [],
                    "extraction_status": "pending",
                    "note": "éœ€è¦åœ¨æœ¬åœ°ç’°å¢ƒæˆ–CIä¸­ä½¿ç”¨pdfplumberæå–å®Œæ•´è¡¨æ ¼æ•¸æ“š"
                }

            print(f"   âœ“ è¡¨æ ¼é–‹å§‹æ–¼ç¬¬ {start_page + 1} é ")

            # ä½¿ç”¨pdfplumberæå–è¡¨æ ¼æ•¸æ“š
            try:
                import pdfplumber

                ingredients = []

                with pdfplumber.open(str(pdf_path)) as pdf:
                    # å¾æ‰¾åˆ°çš„èµ·å§‹é é–‹å§‹æƒæ
                    for page_num in range(start_page, len(pdf.pages)):
                        page = pdf.pages[page_num]
                        tables = page.extract_tables()

                        for table in tables:
                            if not table or len(table) < 2:
                                continue

                            # EUè¡¨æ ¼é€šå¸¸æœ‰5åˆ—ï¼šReference Number, Chemical name/INN, CAS Number, ç­‰
                            for row in table:
                                if len(row) < 3:
                                    continue

                                # è·³éè¡¨é ­è¡Œ
                                first_col = str(row[0] or "").strip().lower()
                                if any(keyword in first_col for keyword in ["reference", "number", "substance"]):
                                    continue

                                # æå–æ•¸æ“š
                                ref_number = self.clean_text(str(row[0])) if row[0] else ""

                                # ç¬¬äºŒåˆ—é€šå¸¸æ˜¯åŒ–å­¸åç¨±æˆ–INNåç¨±
                                chemical_name = self.clean_text(str(row[1])) if row[1] else ""

                                # ç¬¬ä¸‰åˆ—é€šå¸¸æ˜¯CASè™Ÿæˆ–å…¶ä»–è­˜åˆ¥ä¿¡æ¯
                                cas_text = self.clean_text(str(row[2])) if len(row) > 2 and row[2] else ""

                                # è·³éç©ºè¡Œ
                                if not chemical_name or not ref_number:
                                    continue

                                # æå–CASè™Ÿ
                                cas_no = self.extract_cas_number(cas_text)
                                if not cas_no and chemical_name:
                                    # å˜—è©¦å¾åŒ–å­¸åç¨±ä¸­æå–CASè™Ÿ
                                    cas_no = self.extract_cas_number(chemical_name)

                                # æå–å…¶ä»–é™åˆ¶ä¿¡æ¯ï¼ˆç¬¬4ã€5åˆ—ï¼‰
                                restrictions = ""
                                conditions = ""
                                if len(row) > 3 and row[3]:
                                    restrictions = self.clean_text(str(row[3]))
                                if len(row) > 4 and row[4]:
                                    conditions = self.clean_text(str(row[4]))

                                ingredient = {
                                    "reference_number": ref_number,
                                    "chemical_name": chemical_name,
                                    "cas_no": cas_no,
                                    "restrictions": restrictions,
                                    "conditions": conditions,
                                    "annex": config["name"]
                                }

                                ingredients.append(ingredient)

                        # é€²åº¦é¡¯ç¤º
                        if (page_num - start_page) % 10 == 0:
                            print(f"   å·²æƒæåˆ°ç¬¬ {page_num + 1} é ï¼Œæ‰¾åˆ° {len(ingredients)} æ¢è¨˜éŒ„...")

                print(f"   âœ“ æå–å®Œæˆï¼š{len(ingredients)} æ¢è¨˜éŒ„")

                return {
                    "name": config["name"],
                    "pdf_file": pdf_path.name,
                    "pdf_path": str(pdf_path),
                    "table_start_page": start_page + 1,
                    "ingredients_count": len(ingredients),
                    "ingredients": ingredients,
                    "extraction_status": "completed"
                }

            except ImportError:
                print("   âš ï¸  pdfplumberæœªå®‰è£ï¼Œåƒ…è¿”å›çµæ§‹ä¿¡æ¯")
                return {
                    "name": config["name"],
                    "pdf_file": pdf_path.name,
                    "pdf_path": str(pdf_path),
                    "table_start_page": start_page + 1,
                    "ingredients_count": 0,
                    "ingredients": [],
                    "extraction_status": "pending",
                    "note": "éœ€è¦å®‰è£pdfplumber: pip install pdfplumber"
                }

        except Exception as e:
            print(f"   âŒ æå–å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "name": config["name"],
                "pdf_file": pdf_path.name,
                "error": str(e),
                "ingredients_count": 0,
                "ingredients": []
            }


if __name__ == "__main__":
    extractor = EUExtractor()
    result = extractor.run()
    print(f"\næå–çµæœæ‘˜è¦:")
    print(f"ç¸½è¨˜éŒ„æ•¸: {result['metadata']['total_ingredients']}")
