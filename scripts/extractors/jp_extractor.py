"""
JP (Japan) PDF Extractor

å¾æ—¥æœ¬åŒ–å¦å“æ¨™æº–PDFä¸­æå–æ•¸æ“šã€‚

æ•¸æ“šä¾†æºï¼š
- åŒ–ç²§å“åŸºæº– / Standards for Cosmetics
- MHLW (Ministry of Health, Labour and Welfare)
- é™„ä»¶2-1: Standards for Cosmetic Products

åŒ…å«ï¼š
- Negative List (ç¦ç”¨ç‰©è³ª)
- Positive List (æº–ç”¨ç‰©è³ª)
- ä½¿ç”¨åŸºæº– (ä½¿ç”¨æ¨™æº–)
"""

from pathlib import Path
from typing import Dict, List, Any
from .base_extractor import BasePDFExtractor


class JPExtractor(BasePDFExtractor):
    """æ—¥æœ¬æ³•è¦PDFæå–å™¨"""

    def __init__(self):
        super().__init__("JP")

    def extract(self) -> Dict[str, Any]:
        """
        æå–JPæ³•è¦æ•¸æ“š

        Returns:
            æå–çš„æ•¸æ“šå­—å…¸
        """
        # æŸ¥æ‰¾PDFæ–‡ä»¶
        pdf_files = self.find_pdf_files("*é™„ä»¶2-1*Standards*.pdf")

        if not pdf_files:
            pdf_files = self.find_pdf_files()

        if not pdf_files:
            print(f"âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶: {self.raw_data_dir}")
            return {}

        pdf_path = pdf_files[0]
        print(f"ğŸ“„ è™•ç†æ–‡ä»¶: {pdf_path.name}")

        try:
            # ä½¿ç”¨PyPDF2æå–æ–‡æœ¬
            texts = self.extract_text_pypdf2(pdf_path, start_page=0, end_page=100)

            # æŸ¥æ‰¾å„é¡è¡¨æ ¼
            print("\næƒæPDFå…§å®¹...")

            # æŸ¥æ‰¾Appendix 1ï¼ˆç¦ç”¨æ¸…å–®ï¼‰
            prohibited_page = None
            for i, text in enumerate(texts):
                if "Appendix 1" in text or ("ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ" in text or "é…åˆã—ã¦ã¯ãªã‚‰ãªã„" in text):
                    prohibited_page = i
                    print(f"   âœ“ æ‰¾åˆ°ç¦ç”¨æ¸…å–®ï¼ˆAppendix 1ï¼‰æ–¼ç¬¬ {i + 1} é ")
                    break

            # æŸ¥æ‰¾Appendix 2ï¼ˆé™ç”¨æ¸…å–®ï¼‰
            restricted_page = None
            for i, text in enumerate(texts):
                if "Appendix 2" in text:
                    restricted_page = i
                    print(f"   âœ“ æ‰¾åˆ°é™ç”¨æ¸…å–®ï¼ˆAppendix 2ï¼‰æ–¼ç¬¬ {i + 1} é ")
                    break

            # æŸ¥æ‰¾Appendix 3ï¼ˆé˜²è…åŠ‘ã€è‘—è‰²åŠ‘ï¼‰æˆ–Appendix 4ï¼ˆUVéæ¿¾åŠ‘ï¼‰
            positive_page = None
            for i, text in enumerate(texts):
                if "Appendix 3" in text or "Appendix 4" in text or ("ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ" in text or "é…åˆã§ãã‚‹" in text):
                    if positive_page is None:  # åªè¨˜éŒ„ç¬¬ä¸€å€‹
                        positive_page = i
                        print(f"   âœ“ æ‰¾åˆ°æº–ç”¨æ¸…å–®ï¼ˆAppendix 3/4ï¼‰æ–¼ç¬¬ {i + 1} é ")
                        break

            # æå–å¯¦éš›è¡¨æ ¼æ•¸æ“š
            all_data = {}

            # æå–ç¦ç”¨æ¸…å–®
            if prohibited_page is not None:
                all_data["prohibited"] = self.extract_negative_list(pdf_path, prohibited_page)
            else:
                all_data["prohibited"] = {
                    "name": "Appendix 1 - Negative List",
                    "description": "Prohibited ingredients",
                    "ingredients_count": 0,
                    "ingredients": [],
                    "extraction_status": "not_found"
                }

            # æå–é™ç”¨æˆåˆ†
            if restricted_page is not None:
                all_data["restricted"] = self.extract_restricted_list(pdf_path, restricted_page)
            else:
                all_data["restricted"] = {
                    "name": "Appendix 2 - Restricted Ingredients",
                    "ingredients_count": 0,
                    "ingredients": [],
                    "extraction_status": "not_found"
                }

            # æå–æº–ç”¨æ¸…å–®
            if positive_page is not None:
                all_data["positive_list"] = self.extract_positive_list(pdf_path, positive_page)
            else:
                all_data["positive_list"] = {
                    "name": "Appendix 3/4 - Positive List",
                    "description": "Allowed ingredients (preservatives, UV filters, colorants)",
                    "ingredients_count": 0,
                    "ingredients": [],
                    "extraction_status": "not_found"
                }

            # è¨ˆç®—ç¸½æ•¸
            total_count = sum(
                data.get("ingredients_count", 0)
                for data in all_data.values()
                if isinstance(data, dict)
            )

        except Exception as e:
            print(f"âŒ æå–å¤±æ•—: {str(e)}")
            import traceback
            traceback.print_exc()
            all_data = {}
            total_count = 0

        # ç”Ÿæˆè¼¸å‡º
        output = {
            "jurisdiction": "JP",
            "source": "MHLW - Ministry of Health, Labour and Welfare",
            "source_url": "https://www.mhlw.go.jp/stf/seisakunitsuite/bunya/kenkou_iryou/iyakuhin/keshouhin/",
            "regulation": "åŒ–ç²§å“åŸºæº– / Standards for Cosmetics",
            "pdf_path": str(pdf_path),
            "metadata": self.create_metadata(
                total_ingredients=total_count,
                source="MHLW - Ministry of Health, Labour and Welfare",
                regulation="åŒ–ç²§å“åŸºæº– / Standards for Cosmetics",
                published_at="2000-09-29",
                effective_date="2001-04-01"
            ),
            "categories": all_data
        }

        # ä¿å­˜çµæœ
        self.save_json(output, "extracted_latest.json")

        return output

    def extract_negative_list(self, pdf_path: Path, start_page: int) -> Dict[str, Any]:
        """æå–ç¦ç”¨æ¸…å–® (Negative List)"""
        print("\næå–ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ...")

        try:
            import pdfplumber

            ingredients = []

            with pdfplumber.open(str(pdf_path)) as pdf:
                # å¾æ‰¾åˆ°çš„èµ·å§‹é é–‹å§‹æƒæï¼ˆé€šå¸¸ç¦ç”¨æ¸…å–®ä¸æœƒå¤ªé•·ï¼‰
                for page_num in range(start_page, min(start_page + 30, len(pdf.pages))):
                    page = pdf.pages[page_num]
                    tables = page.extract_tables()

                    for table in tables:
                        if not table or len(table) < 2:
                            continue

                        for row in table:
                            if len(row) < 2:
                                continue

                            # è·³éè¡¨é ­
                            first_col = str(row[0] or "").strip()
                            if any(keyword in first_col for keyword in ["ç•ªå·", "æˆåˆ†", "ç‰©è³ª", "No"]):
                                continue

                            # æå–æ•¸æ“š
                            ref_number = self.clean_text(str(row[0])) if row[0] else ""
                            ingredient_name = self.clean_text(str(row[1])) if len(row) > 1 and row[1] else ""

                            # è·³éç©ºè¡Œ
                            if not ingredient_name or not ref_number:
                                continue

                            # æå–CASè™Ÿ
                            cas_no = None
                            if len(row) > 2 and row[2]:
                                cas_text = self.clean_text(str(row[2]))
                                cas_no = self.extract_cas_number(cas_text)

                            ingredient = {
                                "reference_number": ref_number,
                                "ingredient_name": ingredient_name,
                                "cas_no": cas_no,
                                "list_type": "negative"
                            }

                            ingredients.append(ingredient)

                    # é€²åº¦é¡¯ç¤º
                    if (page_num - start_page) % 5 == 0:
                        print(f"   å·²æƒæåˆ°ç¬¬ {page_num + 1} é ï¼Œæ‰¾åˆ° {len(ingredients)} æ¢è¨˜éŒ„...")

            print(f"   âœ“ æå–å®Œæˆï¼š{len(ingredients)} æ¢è¨˜éŒ„")

            return {
                "name": "ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ (Negative List)",
                "description": "é…åˆã—ã¦ã¯ãªã‚‰ãªã„æˆåˆ†",
                "start_page": start_page + 1,
                "ingredients_count": len(ingredients),
                "ingredients": ingredients,
                "extraction_status": "completed"
            }

        except ImportError:
            print("   âš ï¸  pdfplumberæœªå®‰è£")
            return {
                "name": "ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ (Negative List)",
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "pending",
                "note": "éœ€è¦å®‰è£pdfplumber"
            }
        except Exception as e:
            print(f"   âŒ æå–å¤±æ•—: {str(e)}")
            return {
                "name": "ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ (Negative List)",
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "error",
                "error": str(e)
            }

    def extract_restricted_list(self, pdf_path: Path, start_page: int) -> Dict[str, Any]:
        """æå–é™ç”¨æˆåˆ† (Appendix 2)"""
        print("\næå–Appendix 2: Restricted Ingredients...")

        try:
            import pdfplumber

            ingredients = []

            with pdfplumber.open(str(pdf_path)) as pdf:
                # æƒæAppendix 2ï¼ˆé€šå¸¸åŒ…å«å…©å€‹éƒ¨åˆ†ï¼šå…¨éƒ¨åŒ–å¦å“çš„é™ç”¨æˆåˆ† + æŒ‰é¡å‹é™ç”¨çš„æˆåˆ†ï¼‰
                for page_num in range(start_page, min(start_page + 5, len(pdf.pages))):
                    page = pdf.pages[page_num]
                    tables = page.extract_tables()

                    for table in tables:
                        if not table or len(table) < 2:
                            continue

                        for row in table:
                            if len(row) < 2:
                                continue

                            # è·³éè¡¨é ­
                            first_col = str(row[0] or "").strip()
                            if any(keyword in first_col.lower() for keyword in ["ingredient name", "maximum amount", "cosmetics"]):
                                continue

                            # æå–æ•¸æ“šï¼ˆç¬¬ä¸€åˆ—æ˜¯æˆåˆ†åç¨±ï¼Œç¬¬äºŒåˆ—æ˜¯æœ€å¤§é‡ï¼‰
                            ingredient_name = self.clean_text(str(row[0])) if row[0] else ""
                            max_amount = self.clean_text(str(row[1])) if len(row) > 1 and row[1] else ""

                            # è·³éç©ºè¡Œ
                            if not ingredient_name or len(ingredient_name) < 3:
                                continue

                            # æå–CASè™Ÿ
                            cas_no = self.extract_cas_number(ingredient_name)

                            ingredient = {
                                "ingredient_name": ingredient_name,
                                "max_amount": max_amount,
                                "cas_no": cas_no,
                                "list_type": "restricted"
                            }

                            ingredients.append(ingredient)

            print(f"   âœ“ æå–å®Œæˆï¼š{len(ingredients)} æ¢è¨˜éŒ„")

            return {
                "name": "Appendix 2 - Restricted Ingredients",
                "description": "Ingredients with usage restrictions",
                "start_page": start_page + 1,
                "ingredients_count": len(ingredients),
                "ingredients": ingredients,
                "extraction_status": "completed"
            }

        except ImportError:
            print("   âš ï¸  pdfplumberæœªå®‰è£")
            return {
                "name": "Appendix 2 - Restricted Ingredients",
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "pending"
            }
        except Exception as e:
            print(f"   âŒ æå–å¤±æ•—: {str(e)}")
            return {
                "name": "Appendix 2 - Restricted Ingredients",
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "error",
                "error": str(e)
            }

    def extract_positive_list(self, pdf_path: Path, start_page: int) -> Dict[str, Any]:
        """æå–æº–ç”¨æ¸…å–® (Positive List)"""
        print("\næå–ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ...")

        try:
            import pdfplumber

            ingredients = []

            with pdfplumber.open(str(pdf_path)) as pdf:
                # æƒææº–ç”¨æ¸…å–®ï¼ˆå¯èƒ½åŒ…å«é˜²è…åŠ‘ã€UVéæ¿¾åŠ‘ã€è‘—è‰²åŠ‘ç­‰ï¼‰
                for page_num in range(start_page, min(start_page + 50, len(pdf.pages))):
                    page = pdf.pages[page_num]
                    tables = page.extract_tables()

                    for table in tables:
                        if not table or len(table) < 2:
                            continue

                        for row in table:
                            if len(row) < 2:
                                continue

                            # è·³éè¡¨é ­
                            first_col = str(row[0] or "").strip()
                            if any(keyword in first_col for keyword in ["ç•ªå·", "æˆåˆ†", "ç‰©è³ª", "åç§°"]):
                                continue

                            # æå–æ•¸æ“š
                            ingredient_name = self.clean_text(str(row[0])) if row[0] else ""
                            usage = self.clean_text(str(row[1])) if len(row) > 1 and row[1] else ""

                            # è·³éç©ºè¡Œ
                            if not ingredient_name:
                                continue

                            # æå–CASè™Ÿ
                            cas_no = self.extract_cas_number(ingredient_name)
                            if not cas_no and len(row) > 2:
                                cas_no = self.extract_cas_number(str(row[2]))

                            ingredient = {
                                "ingredient_name": ingredient_name,
                                "usage": usage,
                                "cas_no": cas_no,
                                "list_type": "positive"
                            }

                            ingredients.append(ingredient)

                    # é€²åº¦é¡¯ç¤º
                    if (page_num - start_page) % 10 == 0:
                        print(f"   å·²æƒæåˆ°ç¬¬ {page_num + 1} é ï¼Œæ‰¾åˆ° {len(ingredients)} æ¢è¨˜éŒ„...")

            print(f"   âœ“ æå–å®Œæˆï¼š{len(ingredients)} æ¢è¨˜éŒ„")

            return {
                "name": "ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ (Positive List)",
                "description": "é…åˆã§ãã‚‹æˆåˆ†",
                "start_page": start_page + 1,
                "includes": ["é˜²è…åŠ‘", "UVéæ¿¾åŠ‘", "è‘—è‰²åŠ‘"],
                "ingredients_count": len(ingredients),
                "ingredients": ingredients,
                "extraction_status": "completed"
            }

        except ImportError:
            print("   âš ï¸  pdfplumberæœªå®‰è£")
            return {
                "name": "ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ (Positive List)",
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "pending"
            }
        except Exception as e:
            print(f"   âŒ æå–å¤±æ•—: {str(e)}")
            return {
                "name": "ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒªã‚¹ãƒˆ (Positive List)",
                "ingredients_count": 0,
                "ingredients": [],
                "extraction_status": "error",
                "error": str(e)
            }


if __name__ == "__main__":
    extractor = JPExtractor()
    result = extractor.run()
    print(f"\næå–çµæœæ‘˜è¦:")
    print(f"ç¸½è¨˜éŒ„æ•¸: {result['metadata']['total_ingredients']}")
